name: Migrate Bitbucket Repos → Azure DevOps (per-repo project, LFS-aware)

on:
  workflow_dispatch:

jobs:
  migrate-repos:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install prerequisites (tree, git-filter-repo, git-lfs, python3)
        run: |
          set -e
          sudo apt-get update
          sudo apt-get install -y tree python3 python3-pip git-lfs
          git lfs install --system
          pip3 install --upgrade git-filter-repo

      - name: Set up Git identity
        env:
          GIT_USERNAME: ${{ secrets.GIT_USERNAME }}
          GIT_EMAIL: ${{ secrets.GIT_EMAIL }}
        run: |
          git config --global user.name "${GIT_USERNAME:-migration-bot}"
          git config --global user.email "${GIT_EMAIL:-migration-bot@example.com}"

      - name: Migrate (read "bitbucket_ado_repos.txt" → repo,project, filter + LFS)
        env:
          BITBUCKET_USERNAME: ${{ secrets.BITBUCKET_USERNAME }}
          BITBUCKET_APP_PASSWORD: ${{ secrets.BITBUCKET_APP_PASSWORD }}
          AZDO_ORG: ${{ secrets.ADO_ORG }}      # e.g. contoso  (dev.azure.com/contoso)
          AZDO_PAT: ${{ secrets.ADO_PAT }}      # PAT with Repos (Read/Write)
        run: |
          set -euo pipefail

          INPUT_FILE="bitbucket_ado_repos.txt"
          if [[ ! -f "$INPUT_FILE" ]]; then
            echo "ERROR: $INPUT_FILE not found in the repo root."
            exit 1
          fi
          sed -i 's/\r$//' "$INPUT_FILE"   # normalize CRLF

          while IFS=',' read -r raw_bb_url raw_ado_project; do
            [[ -z "${raw_bb_url// }" || "${raw_bb_url}" =~ ^[[:space:]]*# ]] && continue

            bitbucket_repo_url="$(echo "$raw_bb_url" | xargs)"
            ado_project="$(echo "$raw_ado_project" | xargs)"
            if [[ -z "$ado_project" ]]; then
              echo "ERROR: No Azure DevOps project provided for '$bitbucket_repo_url'. Expected 'url,ProjectName'."
              continue
            fi

            # Allow "bitbucket.org/ws/repo.git" or full URL
            if [[ "$bitbucket_repo_url" != http* ]]; then
              bitbucket_repo_url="https://$bitbucket_repo_url"
            fi

            repo_name=$(basename -s .git "$bitbucket_repo_url")
            echo
            echo "=== Migrating '$repo_name' from $bitbucket_repo_url → ADO project '$ado_project' ==="

            # URL-encode project for REST/clone URLs
            ENCODED_AZDO_PROJECT=$(python3 - <<PY
            import urllib.parse,sys
            print(urllib.parse.quote(sys.argv[1]))
            PY
            "$ado_project")

            # Check project exists
            PROJ_API="https://dev.azure.com/${AZDO_ORG}/_apis/projects/${ENCODED_AZDO_PROJECT}?api-version=7.0"
            proj_code=$(curl -sS -o /dev/null -w "%{http_code}" -u ":${AZDO_PAT}" "$PROJ_API")
            if [[ "$proj_code" != "200" ]]; then
              echo "ERROR: ADO project '$ado_project' not found (HTTP $proj_code). Skipping '$repo_name'."
              continue
            fi

            # Repo endpoints
            ADO_API_BASE="https://dev.azure.com/${AZDO_ORG}/${ENCODED_AZDO_PROJECT}/_apis/git"
            REPO_GET_URL="${ADO_API_BASE}/repositories/${repo_name}?api-version=7.0"
            REPO_CREATE_URL="${ADO_API_BASE}/repositories?api-version=7.0"

            echo "Checking if ADO repo '$repo_name' exists in '$ado_project'..."
            http_code=$(curl -sS -o /dev/null -w "%{http_code}" -u ":${AZDO_PAT}" "$REPO_GET_URL")
            if [[ "$http_code" == "200" ]]; then
              echo "Repo already exists."
            else
              echo "Creating ADO repo '$repo_name'..."
              create_code=$(curl -sS -o /dev/null -w "%{http_code}" \
                -u ":${AZDO_PAT}" \
                -H "Content-Type: application/json" \
                -d "{\"name\":\"${repo_name}\"}" \
                "$REPO_CREATE_URL")
              if [[ "$create_code" != "200" && "$create_code" != "201" ]]; then
                echo "ERROR: Failed to create repo '$repo_name' (HTTP $create_code). Skipping."
                continue
              fi
            fi

            # Mirror-clone from Bitbucket
            echo "Cloning (mirror) from Bitbucket..."
            git clone --mirror "https://${BITBUCKET_USERNAME}:${BITBUCKET_APP_PASSWORD}@${bitbucket_repo_url#https://}" "${repo_name}.git"

            pushd "${repo_name}.git" >/dev/null

            # 1) History filter: remove artifact paths ONLY (no size stripping here)
            echo "Filtering history: remove build/, dist/, .cache/ ..."
            git filter-repo \
              --path-glob 'build/**' \
              --path-glob 'dist/**' \
              --path-glob '.cache/**' \
              --invert-paths

            # 2) Hard block: detect any remaining blobs > 250MB after filtering
            echo "Scanning for blobs > 250MB (will block if any are found)..."
            BYTES_250MB=$((250 * 1024 * 1024))
            mkdir -p ../scan
            > ../scan/oversized_over_250MB.txt

            # Enumerate blobs and sizes (simple and robust, may take a bit on huge repos)
            git rev-list --objects --all | while read -r oid path; do
              # Only consider blobs
              type=$(git cat-file -t "$oid" 2>/dev/null || true)
              if [[ "$type" == "blob" ]]; then
                size=$(git cat-file -s "$oid" 2>/dev/null || echo 0)
                if (( size > BYTES_250MB )); then
                  printf "%d\t%s\t%s\n" "$size" "$oid" "$path" >> ../scan/oversized_over_250MB.txt
                fi
              fi
            done

            if [[ -s ../scan/oversized_over_250MB.txt ]]; then
              echo "ERROR: Found blobs > 250MB after path filtering. Migration blocked for '$repo_name'."
              echo "Top offenders (size bytes, oid, path):"
              sort -nr ../scan/oversized_over_250MB.txt | head -n 10
              popd >/dev/null
              rm -rf "${repo_name}.git"
              echo "=== Skipped: $repo_name (oversized blobs present) ==="
              continue
            fi

            # 3) LFS migration: move all blobs >= 90MB into Git LFS across history
            echo "Migrating blobs >= 90MB to Git LFS across history..."
            git lfs install
            git lfs migrate import --everything --above=90MB

            # (Optional) Show a brief LFS summary
            echo "LFS-tracked patterns (.gitattributes):"
            if [[ -f .gitattributes ]]; then
              cat .gitattributes || true
            fi

            # Azure DevOps remote (PAT in URL for non-interactive push)
            ADO_REMOTE="https://${AZDO_ORG}:${AZDO_PAT}@dev.azure.com/${AZDO_ORG}/${ENCODED_AZDO_PROJECT}/_git/${repo_name}"
            git remote add azure "$ADO_REMOTE"

            echo "Pushing mirror (includes rewritten history) to Azure DevOps..."
            git push --mirror azure

            echo "Pushing LFS objects..."
            git lfs push --all azure

            echo "Folder structure (post-filter):"
            tree .

            popd >/dev/null
            rm -rf "${repo_name}.git"
            echo "=== Done: $repo_name → $ado_project ==="
          done < "$INPUT_FILE"
